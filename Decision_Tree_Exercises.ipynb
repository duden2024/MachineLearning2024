{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82416d1b-d41a-4222-b7cf-63d2a76b6571",
   "metadata": {},
   "source": [
    "# Exercise Self information and Entropy\n",
    "Show that -log(p(A)) satisfies all 3 properties required by self-information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2538545-9e1e-4b05-a934-6e9dcbe64371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa41e7-9c25-4833-84fa-a05a2b6cf3ec",
   "metadata": {},
   "source": [
    "## I(1) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e51d7c-f1ad-4dbf-822a-a6c1422e0375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-math.log(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e38eee3-38e9-4fce-9e8d-31212dab8b47",
   "metadata": {},
   "source": [
    "## P(B) > P(A) --> I(A) > I(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a647e08b-edc4-4a49-8bf2-f1680b6b9138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log of 10: \t-2.302585092994046 \n",
      "log of 5:\t-1.6094379124341003\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"log of 10: \\t{-math.log(10)} \n",
    "log of 5:\\t{-math.log(5)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af32a60-9b44-45ef-8d1f-673c7a942a84",
   "metadata": {},
   "source": [
    "## I(A,B) = I(A) + I(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b064bc2-2390-4e54-b8be-cc949acccc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-math.log(3*5) == -math.log(3)-math.log(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ab91e",
   "metadata": {
    "id": "6d8ab91e"
   },
   "source": [
    "## Decision Tree - Exercises\n",
    "\n",
    "This notebook contains exercises concerning decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af9a6f06",
   "metadata": {
    "id": "af9a6f06"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# attribute1: corner ({true, false})\n",
    "# attribute2: blue ({true, false})\n",
    "#\n",
    "\n",
    "circle = 1\n",
    "triangle = 2\n",
    "rectangle = 3\n",
    "\n",
    "A = np.array([  circle, circle, circle, circle, circle, circle,\n",
    "                triangle, triangle, triangle,\n",
    "                rectangle, rectangle, rectangle, rectangle, rectangle\n",
    "                ])\n",
    "\n",
    "B1 = np.array([ triangle, triangle, triangle,\n",
    "                rectangle,rectangle,rectangle,rectangle,rectangle\n",
    "                ])\n",
    "\n",
    "B2 = np.array([circle, circle, circle, circle, circle, circle])\n",
    "\n",
    "C1 =  np.array([ triangle, triangle, triangle,\n",
    "                circle, circle\n",
    "                ])\n",
    "\n",
    "C2 = np.array([circle, circle, circle, circle,\n",
    "                rectangle, rectangle, rectangle, rectangle, rectangle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03537122",
   "metadata": {
    "id": "03537122"
   },
   "source": [
    "### Exercise 1 - Entropy:\n",
    "Implement the entropy in python. Compare your implementation with your calculated values.\n",
    "\n",
    "**Use the following stub for your implementation:**\n",
    "\n",
    "```python\n",
    "def entropy(Y: np.array):\n",
    "    \"\"\" Compute the entropy of a given array of class-labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Y: np.array\n",
    "        A one dimensional numpy array containing class labels. Class labels\n",
    "        are assumed not to be one-hot encoded but categorical integer values.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Entropy of Y.\n",
    "    \"\"\"\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c0a52196",
   "metadata": {
    "id": "c0a52196"
   },
   "outputs": [],
   "source": [
    "def entropy(Y: np.array):\n",
    "    \"\"\" Compute the entropy of a given array of class-labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Y: np.array\n",
    "        A one dimensional numpy array containing class labels. Class labels\n",
    "        are assumed not to be one-hot encoded but categorical integer values.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Entropy of Y.\n",
    "    \"\"\"\n",
    "\n",
    "    # get unique values and counts\n",
    "    unique, counts = np.unique(Y, return_counts=True)\n",
    "    #print(f\"Unique: {unique} \\nCounts: {counts}\")\n",
    "    # number of unique values\n",
    "    n_unique = unique.shape[0]\n",
    "    sum = 0\n",
    "    # entropy function\n",
    "    for i in range(n_unique):\n",
    "        probability = counts[i] / Y.shape[0]\n",
    "        #print(f\"Probability: {probability}\")\n",
    "        log_p = np.log2(probability)\n",
    "        sum -= (probability*log_p)\n",
    "        \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "059d04f7-7d5f-46b9-8978-3909001eb737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropies: \n",
      "A: \t1.5306189948485174 \n",
      "B1: \t0.954434002924965 \n",
      "B2: \t0.0 \n",
      "C1: \t0.9709505944546686 \n",
      "C2: \t0.9910760598382222 \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Entropies: \n",
    "A: \\t{entropy(A)} \n",
    "B1: \\t{entropy(B1)} \n",
    "B2: \\t{entropy(B2)} \n",
    "C1: \\t{entropy(C1)} \n",
    "C2: \\t{entropy(C2)} \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf93cf",
   "metadata": {
    "id": "c3cf93cf"
   },
   "source": [
    "### Exercise 2 - Information Gain:\n",
    "\n",
    "Implement the conditional entropy and information gain. Compare your implementation with your calculated results.\n",
    "\n",
    "**Use the following stubs for your implementation:**\n",
    "\n",
    "```python\n",
    "def conditional_entropy(Sa: list):\n",
    "    \"\"\" Compute the conditional entropy.\n",
    "\n",
    "    Compute the conditional entropy for a list of numpy arrays with given class labels. Each list entry\n",
    "    is assumed to contain the class labels of a set of data that was created by splitting a training set\n",
    "    of data according to an attribute.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Sa: [np.array]\n",
    "        A list of one dimensional numpy arrays each containing class labels. Class labels\n",
    "        are assumed not to be one-hot encoded but categorical integer values.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Entropy of Y.\n",
    "    \"\"\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "```python\n",
    "def information_gain(T : np.array, Sa : list):\n",
    "    \"\"\" Compute the information gain.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T: np.array\n",
    "        A one dimensional numpy array containing class labels. Class labels\n",
    "        are assumed not to be one-hot encoded but categorical integer values.\n",
    "\n",
    "    Sa: [np.array]\n",
    "        A list of one dimensional numpy arrays each containing class labels. Class labels\n",
    "        are assumed not to be one-hot encoded but categorial integer values.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Bits saved when encoding Sa instaed of T.\n",
    "    \"\"\"\n",
    "    pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f090d53",
   "metadata": {
    "id": "3f090d53"
   },
   "outputs": [],
   "source": [
    "def conditional_entropy(Sa: list):\n",
    "    \"\"\" Compute the conditional entropy.\n",
    "\n",
    "    Compute the conditional entropy for a list of numpy arrays with given class labels. Each list entry\n",
    "    is assumed to contain the class labels of a set of data that was created by splitting a training set\n",
    "    of data according to an attribute.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Sa: [np.array]\n",
    "        A list of one dimensional numpy arrays each containing class labels. Class labels\n",
    "        are assumed not to be one-hot encoded but categorical integer values.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Conditional entropy of Sa.\n",
    "    \"\"\"\n",
    "    # create array containing all values\n",
    "    T = np.concatenate((Sa[0], Sa[1]))\n",
    "    # initialize sum\n",
    "    sum = 0\n",
    "    # conditional entropy function for every element\n",
    "    for s in Sa:\n",
    "        sum += (len(s) / len(T)) * entropy(s)\n",
    "        \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "21d1d81f-6238-4d95-b443-b56e3f0d4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sa = [B1, B2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa6de16f-a369-478a-8cae-15bbd9e2f7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5453908588142657"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_entropy(Sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "03688e78-c386-48f8-abfe-28966c7893a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(T : np.array, Sa : list):\n",
    "    \"\"\" Compute the information gain.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T: np.array\n",
    "        A one dimensional numpy array containing class labels. Class labels\n",
    "        are assumed not to be one-hot encoded but categorical integer values.\n",
    "\n",
    "    Sa: [np.array]\n",
    "        A list of one dimensional numpy arrays each containing class labels. Class labels\n",
    "        are assumed not to be one-hot encoded but categorial integer values.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Bits saved when encoding Sa instaed of T.\n",
    "    \"\"\"\n",
    "    return entropy(T) - conditional_entropy(Sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "13de1193-5042-4c72-a969-12ca13720308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852281360342516"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain(A, Sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435022ff",
   "metadata": {
    "id": "435022ff"
   },
   "source": [
    "### Exercise 3 - Gini Impurity:\n",
    "\n",
    "Implement the Gini Impurity and compare your results with your calculations.\n",
    "\n",
    "**Use the following stubs for your implementation:**\n",
    "\n",
    "```python\n",
    "def gini_impurity(Y:np.array):\n",
    "   \"\"\" Compute the gini impurity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Y: np.array\n",
    "        A one dimensional numpy array containing class labels. Class labels\n",
    "        are assumed not to be one-hot encoded but categorical integer values.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Gini impurity of the set with labels Y.\n",
    "    \"\"\"\n",
    "    pass\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc60e462",
   "metadata": {
    "id": "fc60e462"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e44a472d",
   "metadata": {
    "id": "e44a472d"
   },
   "source": [
    "### Exercise 4 - Decision Tree in scikit-learn:\n",
    "\n",
    "Let's now use a full implementation of decision trees from scikit-learn.\n",
    "\n",
    "* Build a decision tree using **gini impurity** and a decision tree using **entropy** based on the implementation in sklearn (https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "* Interpret and compare the results by using the ```plot_tree()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db63a83",
   "metadata": {
    "id": "2db63a83"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "Y = np.array([  circle, circle, circle, circle, circle, circle,\n",
    "                triangle, triangle, triangle,\n",
    "                rectangle, rectangle, rectangle, rectangle, rectangle\n",
    "            ])\n",
    "\n",
    "# Attributes (aka Features)\n",
    "# x1 = corners, x2 = blue\n",
    "# Notice that sklearn does not support categorical attributes we therefore encode this\n",
    "# (one-hot-encoded) by using 0 as False and 1 as True.\n",
    "#\n",
    "X = np.array([[0, 1],  # circle 1\n",
    "              [0, 1],  # circle 2\n",
    "              [0, 0], # circle 3\n",
    "              [0, 0], # circle 4\n",
    "              [0, 0], # circle 5\n",
    "              [0, 0], # circle 6\n",
    "              [1, 1],   # triangle 1\n",
    "              [1, 1],   # triangle 2\n",
    "              [1, 1],   # triangle 3\n",
    "              [1, 0],  # rectangle 1\n",
    "              [1, 0],  # rectangle 2\n",
    "              [1, 0],  # rectangle 3\n",
    "              [1, 0],  # rectangle 4\n",
    "              [1, 0]   # rectangle 5\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72298ef",
   "metadata": {
    "id": "f72298ef"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8a75f54",
   "metadata": {
    "id": "c8a75f54"
   },
   "source": [
    "### Exercise 5 - Experiment with Decision Trees in scikit-learn:\n",
    "\n",
    "In this exercise it is your job to experiment with the decision tree implementation of sklearn. I provided you with a ```gen_data()``` method\n",
    "which is capable of generating (random) data. Use the ```accuracy_score()``` method from sklearn.metrics for evaluation. Train a classifier for this synthetic data and try to answer the following questions:\n",
    "\n",
    "* How does the accuracy change depending on the number of data?\n",
    "* Create a seperate dataset for training and testing, what is the difference between training and test accuracy? Why is it different?\n",
    "* Restrict the depth of the decision tree, what changes?\n",
    "* Have a closer look on the decisions in a tree. Explain the results. (Note: You can increase the size of the plotted tree using this line of code ```plt.figure(figsize=(20,20))``` before calling the ```tree.plot_tree``` method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6932a5",
   "metadata": {
    "id": "eb6932a5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_data(num_samples=10):\n",
    "\n",
    "    std = 10\n",
    "    mean = 0\n",
    "\n",
    "    X = std * np.random.uniform(0, 1, (num_samples, 2)) + mean\n",
    "    Y = np.zeros(num_samples)\n",
    "    Y[0:int(num_samples/2)] = 1\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(X[0:int(num_samples/2),0], X[0:int(num_samples/2),1])\n",
    "    plt.scatter(X[int(num_samples/2):-1,0], X[int(num_samples/2):-1,1])\n",
    "    plt.legend(['Class-1', 'Class-2'])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a4467",
   "metadata": {
    "id": "de5a4467"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbbe0c6b",
   "metadata": {
    "id": "dbbe0c6b"
   },
   "source": [
    "### Exercise 6 - Condition monitoring of hydraulic systems sata set\n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems\n",
    "\n",
    "* Load the dataset and use a DecisionTree to classify it.\n",
    "* Make sure you are using a test- and train-split.\n",
    "* Try to predict the different type of faults using decision trees.\n",
    "* Explain what attributes the trees select.\n",
    "\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "The data set was experimentally obtained with a hydraulic test rig. This test rig consists of a primary working and a secondary cooling-filtration circuit which are connected via the oil tank [1], [2]. The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values such as pressures, volume flows and temperatures while the condition of four hydraulic components (cooler, valve, pump and accumulator) is quantitatively varied.\n",
    "\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "The data set was experimentally obtained with a hydraulic test rig. This test rig consists of a primary working and a secondary cooling-filtration circuit which are connected via the oil tank [1], [2]. The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values such as pressures, volume flows and temperatures while the condition of four hydraulic components (cooler, valve, pump and accumulator) is quantitatively varied.\n",
    "\n",
    "**Attributes are:**\n",
    "```\n",
    "Attribute   Sensor\t    Physical quantity\t\t        Unit\t    Sampling rate\n",
    "X[0]           PS1\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "X[1]           PS2\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "X[2]           PS3\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "X[3]           PS4\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "X[4]           PS5\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "X[5]           PS6\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "X[6]           EPS1             Motor power\t\t\tW\t\t100 Hz\n",
    "X[7]           FS1\t\tVolume flow\t\t\tl/min\t\t10 Hz\n",
    "X[8]           FS2\t\tVolume flow\t\t\tl/min\t\t10 Hz\n",
    "X[9]           TS1\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "X[10]          TS2\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "X[11]          TS3\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "X[12]          TS4\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "X[13]          VS1\t\tVibration\t\t\tmm/s\t\t1 Hz\n",
    "X[14]          CE\t\tCooling efficiency (virtual)\t%\t\t1 Hz\n",
    "X[15]          CP\t\tCooling power (virtual)\t\tkW\t\t1 Hz\n",
    "X[16]          SE\t\tEfficiency factor\t\t%\t\t1 Hz\n",
    "```\n",
    "\n",
    "The target conditions are:\n",
    "\n",
    "**1: Cooler condition / %:***\n",
    "* 3: close to total failure\n",
    "* 20: reduced effifiency\n",
    "* 100: full efficiency\n",
    "\n",
    "**2: Valve condition / %:**\n",
    "* 100: optimal switching behavior\n",
    "* 90: small lag\n",
    "* 80: severe lag\n",
    "* 73: close to total failure\n",
    "\n",
    "**3: Internal pump leakage:**\n",
    "* 0: no leakage\n",
    "* 1: weak leakage\n",
    "* 2: severe leakage\n",
    "\n",
    "**4: Hydraulic accumulator / bar:**\n",
    "* 130: optimal pressure\n",
    "* 115: slightly reduced pressure\n",
    "* 100: severely reduced pressure\n",
    "* 90: close to total failure\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801baa02",
   "metadata": {
    "id": "801baa02"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/condition_monitoring.pickle -P ../data\n",
    "\n",
    "import pickle\n",
    "import numpy as  np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    Description: str\n",
    "    Attributes: list()\n",
    "    Targets_cooler: list()\n",
    "    Targets_valve: list()\n",
    "    Targets_leakage: list()\n",
    "    Targets_accu: list()\n",
    "    X: np.array\n",
    "    Y_cooler: np.array\n",
    "    Y_valve: np.array\n",
    "    Y_leakage: np.array\n",
    "    Y_accu: np.array\n",
    "\n",
    "def load_dataset(filename):\n",
    "    with open(filename, 'rb') as fd:\n",
    "        dataset = pickle.load(fd)\n",
    "    return dataset\n",
    "\n",
    "data = load_dataset('../data/condition_monitoring.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9dbff",
   "metadata": {
    "id": "49c9dbff"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "71e3996440a4286f4b5430a3d4d1ae66fa68d894e5edac3334c7ebe5f98b7546"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
